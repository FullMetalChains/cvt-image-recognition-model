{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":4328878,"sourceType":"datasetVersion","datasetId":2549275},{"sourceId":11574137,"sourceType":"datasetVersion","datasetId":7256556}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Install required packages\n!pip install rembg onnxruntime pillow numpy opencv-python albumentations tqdm psutil\n\nimport os\nimport cv2\nimport numpy as np\nfrom tqdm import tqdm\nimport albumentations as A\nimport random\nfrom PIL import Image\nimport shutil\nimport zipfile  # Add zipfile module for creating zip archives\nimport gc\nimport psutil  # For monitoring memory usage\n\n# Import rembg after installation\nfrom rembg import remove, new_session\n\n# Input and output paths\ninput_dir = \"/kaggle/input/indian-sign-language-self-creation/isl_dataset\"\noutput_dir = \"/kaggle/working/augmented_isl_dataset\"\nbackground_dir = \"/kaggle/input/house-rooms-streets-image-dataset/kaggle_room_street_data/house_data\"\ntemp_dir = \"/kaggle/working/temp\"\n\n# Function to clean memory\ndef clean_memory():\n    \"\"\"Force garbage collection and report memory usage\"\"\"\n    gc.collect()\n    process = psutil.Process(os.getpid())\n    mem_info = process.memory_info()\n    print(f\"Memory usage: {mem_info.rss / 1024 / 1024:.2f} MB\")\n\n# Function to check available disk space\ndef check_disk_space(min_required_mb=500):\n    \"\"\"Check if there's enough disk space available\"\"\"\n    disk_usage = shutil.disk_usage(\"/kaggle/working\")\n    available_mb = disk_usage.free / (1024 * 1024)\n    print(f\"Available disk space: {available_mb:.2f} MB\")\n    return available_mb >= min_required_mb\n\n# Create output directories\nos.makedirs(output_dir, exist_ok=True)\nos.makedirs(temp_dir, exist_ok=True)\n\n# Load human segmentation model from rembg\nprint(\"Loading segmentation model...\")\n# You can try different models: \"u2net_human_seg\" (human-specific) or \"u2net\" (general)\nmodel_name = \"u2net_human_seg\"  # Human-specific segmentation model\n# model_name = \"birefnet-portrait\"\nsession = new_session(model_name)\nprint(f\"Using segmentation model: {model_name}\")\n\n# Function to load background images\ndef load_background_images(bg_dir, max_images=100):\n    print(\"Loading background images...\")\n    bg_images = []\n    valid_prefixes = ['bed', 'din', 'kitchen', 'living']\n    \n    # List all files in the background directory\n    for filename in os.listdir(bg_dir):\n        if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n            # Check if filename starts with valid prefixes\n            prefix = filename.split('_')[0] if '_' in filename else ''\n            if prefix in valid_prefixes:\n                bg_path = os.path.join(bg_dir, filename)\n                bg_images.append(bg_path)\n                if len(bg_images) >= max_images:  # Limit number of background images\n                    break\n    \n    print(f\"Found {len(bg_images)} valid background images\")\n    return bg_images\n\n# Load background images - only load a subset to save memory\nbackground_images = load_background_images(background_dir, max_images=1000)\nclean_memory()\n\n# Function for histogram equalization to normalize brightness\ndef equalize_brightness(image):\n    \"\"\"\n    Apply histogram equalization to normalize brightness across images.\n    Works in HSV color space to preserve hue while equalizing value channel.\n    \n    Args:\n        image: Input image as numpy array (BGR format)\n        \n    Returns:\n        Image with equalized brightness\n    \"\"\"\n    # Convert to HSV\n    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n    \n    # Equalize the V channel\n    hsv[:,:,2] = cv2.equalizeHist(hsv[:,:,2])\n    \n    # Convert back to BGR\n    result = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n    \n    # Clean up intermediate variables\n    del hsv\n    return result\n\n# Function for unsharp masking to sharpen images\ndef unsharp_mask(image, kernel_size=(5, 5), sigma=1.0, amount=1.0, threshold=0):\n    \"\"\"\n    Apply unsharp masking to sharpen an image.\n    \n    Args:\n        image: Input image as numpy array\n        kernel_size: Size of Gaussian blur kernel\n        sigma: Standard deviation of Gaussian blur\n        amount: Weight of sharpening effect (higher = sharper)\n        threshold: Minimum brightness difference to apply sharpening\n        \n    Returns:\n        Sharpened image\n    \"\"\"\n    # Create the blurred version of the image\n    blurred = cv2.GaussianBlur(image, kernel_size, sigma)\n    \n    # Calculate the high-frequency details\n    sharpened = float(amount + 1) * image - float(amount) * blurred\n    \n    # Clip the values to valid range and convert back to uint8\n    sharpened = np.clip(sharpened, 0, 255).astype(np.uint8)\n    \n    # Apply threshold mask if specified\n    if threshold > 0:\n        low_contrast_mask = np.absolute(image - blurred) < threshold\n        sharpened[low_contrast_mask] = image[low_contrast_mask]\n    \n    # Clean up\n    del blurred, low_contrast_mask\n    return sharpened\n\n# Function for adaptive brightness normalization using CLAHE\ndef adaptive_brightness_normalization(image, clip_limit=2.0, tile_grid_size=(8, 8)):\n    \"\"\"\n    Apply Contrast Limited Adaptive Histogram Equalization (CLAHE)\n    for more localized brightness normalization.\n    \n    Args:\n        image: Input image (BGR format)\n        clip_limit: Threshold for contrast limiting\n        tile_grid_size: Size of grid for histogram equalization\n        \n    Returns:\n        Image with adaptively normalized brightness\n    \"\"\"\n    # Convert to LAB color space (L channel is for lightness)\n    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n    \n    # Create CLAHE object\n    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)\n    \n    # Apply CLAHE to L channel\n    lab[:,:,0] = clahe.apply(lab[:,:,0])\n    \n    # Convert back to BGR\n    result = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n    \n    # Clean up\n    del lab, clahe\n    return result\n\ndef remove_background(image, background_images):\n    # No resizing - preserve original image dimensions\n    \n    try:\n        # Choose between standard histogram equalization and adaptive CLAHE\n        use_adaptive = True  # Set to False to use standard equalization\n        \n        if use_adaptive:\n            # Apply adaptive brightness normalization using CLAHE\n            image = adaptive_brightness_normalization(image, clip_limit=2.0, tile_grid_size=(8, 8))\n        else:\n            # Apply standard histogram equalization to normalize brightness\n            image = equalize_brightness(image)\n        \n        # Apply unsharp masking to sharpen the image\n        image = unsharp_mask(image, kernel_size=(5, 5), sigma=1.0, amount=1.5, threshold=5)\n        \n        # Convert OpenCV image (BGR) to PIL Image (RGB)\n        if isinstance(image, np.ndarray):\n            pil_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n        else:\n            pil_image = image\n        \n        # Remove background using rembg\n        output_image = remove(pil_image, \n                            session=session,\n                            alpha_matting=True,\n                            alpha_matting_foreground_threshold=240,\n                            alpha_matting_background_threshold=10,\n                            alpha_matting_erode_size=10,\n                            post_process_mask=True)\n        \n        # Free memory\n        del pil_image\n        \n        # Convert back to numpy array for further processing\n        output_array = np.array(output_image)\n        del output_image\n        \n        # Extract alpha channel as mask\n        if output_array.shape[2] == 4:\n            mask = output_array[:, :, 3] / 255.0\n            rgb_image = output_array[:, :, :3]\n            \n            # Improve mask with morphological operations\n            # Convert mask to binary image\n            binary_mask = (mask > 0.5).astype(np.uint8)\n            \n            # Apply morphological closing to fill small holes\n            kernel = np.ones((5, 5), np.uint8)\n            improved_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_CLOSE, kernel)\n            \n            # Apply dilation to expand the mask slightly and recover potentially missing body parts\n            improved_mask = cv2.dilate(improved_mask, kernel, iterations=1)\n            \n            # Convert back to float mask\n            mask = improved_mask.astype(float)\n            \n            # Clean up intermediate variables\n            del binary_mask, improved_mask, kernel\n        else:\n            del output_array\n            return np.array(pil_image)\n        \n        # Apply skin transformation (new code)\n        # Convert to HSV for better skin detection\n        hsv_image = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2HSV)\n        \n        # Define HSV range for common skin tones (this is a basic approach and may need adjustment)\n        lower_skin = np.array([0, 20, 70], dtype=np.uint8)\n        upper_skin = np.array([20, 150, 255], dtype=np.uint8)\n        \n        # Create a binary mask of skin regions\n        skin_mask = cv2.inRange(hsv_image, lower_skin, upper_skin)\n        \n        # Option 1: Remove skin color by desaturating it\n        # Where skin is detected, reduce saturation to make it grayscale\n        hsv_image[skin_mask > 0, 1] = 30  # Lower saturation value\n        \n        # Convert back to RGB color space\n        rgb_image = cv2.cvtColor(hsv_image, cv2.COLOR_HSV2RGB)\n        \n        # Clean up\n        del hsv_image, skin_mask, lower_skin, upper_skin\n        \n        # Use random house background instead of computer-generated background\n        if background_images:\n            # Select a random background image\n            bg_path = random.choice(background_images)\n            \n            try:\n                # Load the background image\n                background = cv2.imread(bg_path)\n                if background is None:\n                    raise Exception(f\"Could not load background image: {bg_path}\")\n                \n                # Convert from BGR to RGB\n                background = cv2.cvtColor(background, cv2.COLOR_BGR2RGB)\n                \n                # Resize background to match foreground image size\n                h, w = rgb_image.shape[:2]\n                background = cv2.resize(background, (w, h))\n                \n                # Apply histogram equalization to the background for consistent brightness\n                background_bgr = cv2.cvtColor(background, cv2.COLOR_RGB2BGR)\n                background_eq = equalize_brightness(background_bgr)\n                background = cv2.cvtColor(background_eq, cv2.COLOR_BGR2RGB)\n                \n                # Clean up\n                del background_bgr, background_eq\n                \n            except Exception as e:\n                print(f\"Error loading background image ({bg_path}): {str(e)}\")\n                # Fallback to a solid color background if loading fails\n                bg_color = np.array([random.randint(0, 255), \n                                    random.randint(0, 255), \n                                    random.randint(0, 255)])\n                background = np.ones_like(rgb_image) * bg_color.reshape(1, 1, 3)\n                del bg_color\n        else:\n            # Fallback if no background images are available\n            print(\"Warning: No background images available, using solid color.\")\n            bg_color = np.array([random.randint(0, 255), \n                                random.randint(0, 255), \n                                random.randint(0, 255)])\n            background = np.ones_like(rgb_image) * bg_color.reshape(1, 1, 3)\n            del bg_color\n        \n        # Merge foreground and background using mask\n        mask_3d = np.expand_dims(mask, axis=2).repeat(3, axis=2)\n        segmented_image = (rgb_image * mask_3d + background * (1 - mask_3d)).astype(np.uint8)\n        \n        # Clean up\n        del mask, mask_3d, rgb_image, background, output_array\n        \n        return segmented_image\n    \n    except Exception as e:\n        print(f\"Error in remove_background: {str(e)}\")\n        # Return original image if processing fails\n        return image\n\n# Enhanced augmentation pipeline with more diverse transformations\naugmentation = A.Compose([\n    # Color transformations (reduced probabilities)\n    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.4),\n    A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=15, val_shift_limit=10, p=0.3),\n    A.CLAHE(clip_limit=2.0, tile_grid_size=(8, 8), p=0.2),\n    A.ToGray(p=0.05),  # Reduced probability\n    \n    # Additional color manipulations (reduced probabilities)\n    A.RGBShift(r_shift_limit=15, g_shift_limit=15, b_shift_limit=15, p=0.2),\n    A.ChannelShuffle(p=0.05),  # Reduced probability\n    A.ChannelDropout(channel_drop_range=(1, 1), fill_value=0, p=0.05),  # Reduced probability\n    \n    # New advanced color transforms with low probabilities\n    A.RandomGamma(gamma_limit=(80, 120), p=0.1),  # Random gamma adjustment\n    A.FancyPCA(alpha=0.1, p=0.05),  # Add color perturbations along principal components\n    \n    # Noise and blur effects (significantly reduced)\n    A.GaussNoise(var_limit=(1.0, 8.0), p=0.1),  # Significantly reduced variance and probability\n    A.GaussianBlur(blur_limit=(1, 3), p=0.1),  # Reduced probability\n    A.MotionBlur(blur_limit=3, p=0.05),  # Reduced blur limit and probability\n    A.ISONoise(color_shift=(0.01, 0.02), intensity=(0.05, 0.2), p=0.1),  # Reduced intensity and probability\n    A.PixelDropout(dropout_prob=0.001, p=0.05),  # Significantly reduced dropout probability\n    \n    # New blur and texture effects\n    A.AdvancedBlur(blur_limit=(3, 5), p=0.05),  # More sophisticated blur\n    A.Defocus(radius=(2, 4), alias_blur=(0.1, 0.5), p=0.05),  # Defocus blur\n    A.Superpixels(p_replace=0.1, n_segments=100, p=0.05),  # Superpixel segmentation\n    A.UnsharpMask(blur_limit=(3, 5), p=0.05),  # Sharpening through unsharp mask\n    A.RingingOvershoot(blur_limit=(3, 5), p=0.05),  # Ringing artifacts like from JPEG compression\n    \n    # Enhanced geometric transformations (adjusted probabilities)\n    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.15, rotate_limit=15, \n                      border_mode=cv2.BORDER_CONSTANT, p=0.4),  # Reduced probability\n    A.Perspective(scale=(0.05, 0.15), p=0.3),  # Reduced probability\n    A.GridDistortion(num_steps=5, distort_limit=0.2, p=0.15),  # Reduced probability\n    A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=0.1),  # Reduced probability\n    \n    # Lens distortion simulation\n    A.OpticalDistortion(distort_limit=0.2, shift_limit=0.1, p=0.15),  # Reduced probability\n])\n\n# Reduced number of augmentations per image to save space\nnum_augmentations = 4  # Restored to original number\n\n# Function to clean temporary files to free up space\ndef clean_temp_files():\n    \"\"\"Remove all files in the temp directory\"\"\"\n    if os.path.exists(temp_dir):\n        for file in os.listdir(temp_dir):\n            file_path = os.path.join(temp_dir, file)\n            if os.path.isfile(file_path):\n                os.remove(file_path)\n    print(\"Temporary files cleaned.\")\n\n# Batch processing function to handle subsets of classes\ndef process_class_batch(class_batch, batch_index, total_batches):\n    global processed_count\n    \n    for class_folder in tqdm(class_batch, desc=f\"Processing batch {batch_index+1}/{total_batches}\"):\n        class_path = os.path.join(input_dir, class_folder)\n        \n        # Skip if not a directory\n        if not os.path.isdir(class_path):\n            continue\n        \n        # Create output class folder\n        output_class_dir = os.path.join(output_dir, class_folder)\n        os.makedirs(output_class_dir, exist_ok=True)\n        \n        # Get all images in this class\n        image_files = [f for f in os.listdir(class_path) \n                      if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n        \n        # Process only a subset of images if the directory is too large\n        max_images_per_class = 100  # Reduced limit of images per class\n        if len(image_files) > max_images_per_class:\n            image_files = image_files[:max_images_per_class]\n        \n        # Process each image\n        for img_file in tqdm(image_files, desc=f\"Processing {class_folder}\", leave=False):\n            # Check disk space before processing\n            if not check_disk_space(min_required_mb=200):  # Need at least 200MB free\n                print(\"WARNING: Low disk space. Cleaning temporary files...\")\n                clean_temp_files()\n                clean_memory()\n                if not check_disk_space(min_required_mb=100):\n                    print(\"CRITICAL: Extremely low disk space. Skipping further processing.\")\n                    return\n            \n            img_path = os.path.join(class_path, img_file)\n            \n            # Skip processing if output already exists to avoid duplicates\n            base_name, _ = os.path.splitext(img_file)\n            original_output_path = os.path.join(output_class_dir, base_name + \".png\")\n            if os.path.exists(original_output_path):\n                continue\n            \n            # Read the image\n            image = cv2.imread(img_path)\n            if image is None:\n                print(f\"Warning: Could not read {img_path}\")\n                continue\n            \n            try:\n                # Remove background and add a new one\n                segmented_image = remove_background(image, background_images)\n                \n                # Free original image memory\n                del image\n                \n                # Save segmented original image as PNG with compression\n                cv2.imwrite(original_output_path, cv2.cvtColor(segmented_image, cv2.COLOR_RGB2BGR))\n                \n                # Generate augmented versions (fewer than before)\n                for i in range(num_augmentations):\n                    augmented = augmentation(image=segmented_image)\n                    aug_image = augmented['image']\n                    \n                    # Create augmented filename\n                    aug_filename = f\"{base_name}_aug{i+1}.png\"\n                    aug_output_path = os.path.join(output_class_dir, aug_filename)\n                    \n                    # Save augmented image as PNG with compression\n                    cv2.imwrite(aug_output_path, cv2.cvtColor(aug_image, cv2.COLOR_RGB2BGR))\n                    \n                    # Free augmented image memory\n                    del aug_image\n                \n                # Free segmented image memory\n                del segmented_image\n                \n                processed_count += 1\n                \n                # Clear memory more frequently\n                if processed_count % 10 == 0:\n                    clean_memory()\n                    \n            except Exception as e:\n                print(f\"Error processing {img_path}: {str(e)}\")\n                # If segmentation fails, save the original image with compression\n                if 'image' in locals():\n                    cv2.imwrite(original_output_path, image)\n                    del image\n        \n        # Clean up after each class to free space\n        clean_temp_files()\n        clean_memory()\n\n# Function to zip processed files in smaller batches\ndef create_zip_in_batches(source_dir, zip_path, batch_size=100):\n    \"\"\"\n    Create a zip file in batches to avoid memory issues\n    \n    Args:\n        source_dir: Directory to zip\n        zip_path: Path to save the zip file\n        batch_size: Number of files to process in each batch\n    \"\"\"\n    print(f\"Creating zip archive of {source_dir} in batches...\")\n    \n    # Count total files to zip\n    total_files = 0\n    for root, _, files in os.walk(source_dir):\n        total_files += len(files)\n    \n    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n        file_count = 0\n        batch_count = 0\n        \n        for root, _, files in os.walk(source_dir):\n            for i, file in enumerate(files):\n                if file_count % batch_size == 0:\n                    batch_count += 1\n                    print(f\"Processing batch {batch_count} ({file_count}/{total_files} files)\")\n                    # Force garbage collection between batches\n                    clean_memory()\n                    \n                    # Check disk space\n                    if not check_disk_space(min_required_mb=100):\n                        print(\"WARNING: Low disk space during zip creation. Trying to free up space...\")\n                        # Try to remove some files that have already been zipped\n                        # This is risky but might be necessary in extreme space constraints\n                        for sub_root, _, sub_files in os.walk(source_dir):\n                            for sub_file in sub_files[:5]:  # Remove up to 5 files\n                                if os.path.exists(os.path.join(sub_root, sub_file)):\n                                    os.remove(os.path.join(sub_root, sub_file))\n                \n                file_path = os.path.join(root, file)\n                arc_path = os.path.relpath(file_path, os.path.dirname(source_dir))\n                \n                try:\n                    # Add file to zip\n                    zipf.write(file_path, arc_path)\n                    \n                    # Delete original file after adding to zip to save space\n                    os.remove(file_path)\n                    \n                    file_count += 1\n                except Exception as e:\n                    print(f\"Error adding {file_path} to zip: {str(e)}\")\n                \n                # Check if we need to stop due to space issues\n                if file_count % 10 == 0 and not check_disk_space(min_required_mb=50):\n                    print(\"CRITICAL: Extremely low disk space. Stopping zip creation.\")\n                    break\n            \n            # Clean empty directories\n            if len(os.listdir(root)) == 0 and root != source_dir:\n                os.rmdir(root)\n\n# Main processing function\ndef main():\n    global processed_count\n    processed_count = 0\n    \n    try:\n        # Get all class folders\n        class_folders = [d for d in os.listdir(input_dir) if os.path.isdir(os.path.join(input_dir, d))]\n        \n        # Process in smaller batches\n        batch_size = 5  # Process 5 classes at a time\n        num_batches = (len(class_folders) + batch_size - 1) // batch_size\n        \n        for i in range(num_batches):\n            start_idx = i * batch_size\n            end_idx = min((i + 1) * batch_size, len(class_folders))\n            batch = class_folders[start_idx:end_idx]\n            \n            # Process this batch\n            process_class_batch(batch, i, num_batches)\n            \n            # Check if we should continue\n            if not check_disk_space(min_required_mb=500):\n                print(\"Low disk space. Creating zip archive of processed data so far...\")\n                create_zip_in_batches(output_dir, \"/kaggle/working/augmented_isl_dataset_partial.zip\")\n                # Clean up the output directory after zipping\n                shutil.rmtree(output_dir)\n                os.makedirs(output_dir, exist_ok=True)\n        \n        print(f\"Dataset processing complete. Augmented dataset saved to {output_dir}\")\n        print(f\"The dataset maintains the original directory structure with {num_augmentations} augmented copies per image.\")\n        print(f\"Total processed images: {processed_count}\")\n        \n        # Create a zip archive of the processed dataset in batches\n        print(\"Creating final zip archive...\")\n        zip_filename = \"/kaggle/working/augmented_isl_dataset.zip\"\n        create_zip_in_batches(output_dir, zip_filename)\n        \n        # Remove the unzipped directory to save space\n        print(f\"Removing the unzipped directory {output_dir} to save space...\")\n        shutil.rmtree(output_dir)\n        print(\"Unzipped directory removed successfully.\")\n        \n        # Clean up temp directory\n        clean_temp_files()\n        if os.path.exists(temp_dir):\n            shutil.rmtree(temp_dir)\n        \n        # Final memory cleanup\n        clean_memory()\n        \n    except Exception as e:\n        print(f\"Error in main processing: {str(e)}\")\n        # Try to clean up even if there's an error\n        clean_temp_files()\n        clean_memory()\n\n# Run the main function\nif __name__ == \"__main__\":\n    main() ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}